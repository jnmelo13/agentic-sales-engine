{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# B2B Agent Workflow\n",
    "\n",
    "This notebook demonstrates the B2B Agent multi-agent workflow system for lead finding, collection, and enrichment.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.message import add_messages\n",
    "from dotenv import load_dotenv\n",
    "from IPython.display import Image, display\n",
    "import gradio as gr\n",
    "from langgraph.graph import StateGraph\n",
    "from langgraph.graph.message import add_messages\n",
    "from langchain_openai import ChatOpenAI\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import Optional\n",
    "import random\n",
    "from langchain_core.messages import ToolMessage\n",
    "\n",
    "# Add memory\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "memory = MemorySaver()\n",
    "\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from langchain_mcp_adapters.client import MultiServerMCPClient\n",
    "\n",
    "async def get_mcp_client():\n",
    "    client = MultiServerMCPClient(\n",
    "        {\n",
    "            \"google_workspace\": {\n",
    "                \"transport\": \"streamable_http\",\n",
    "                \"url\": f\"{os.getenv('WORKSPACE_MCP_BASE_URI', 'http://localhost')}:{os.getenv('WORKSPACE_MCP_PORT', '8001')}/mcp\",\n",
    "            }\n",
    "        }\n",
    "    )\n",
    "    return client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get MCP tools (async)\n",
    "# mcp_client = await get_mcp_client()\n",
    "# mcp_tools = await mcp_client.get_tools()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mcp_tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "\n",
    "from pydantic import BaseModel, Field\n",
    "\n",
    "\n",
    "class Lead(BaseModel):\n",
    "    \"\"\"Structured lead with enrichment fields.\"\"\"\n",
    "\n",
    "    company: str\n",
    "    industry: str\n",
    "    employee_count: int\n",
    "    revenue_musd: float\n",
    "\n",
    "    # Enrichment fields - initially None\n",
    "    website: Optional[str] = None\n",
    "    last_year_profit: Optional[float] = None\n",
    "    last_quarter_ebitda: Optional[float] = None\n",
    "    stock_variation_3m: Optional[float] = None\n",
    "\n",
    "    def needs_enrichment(self) -> bool:\n",
    "        \"\"\"Check if lead still needs enrichment.\"\"\"\n",
    "        return (\n",
    "            self.website is None\n",
    "            or self.last_year_profit is None\n",
    "            or self.last_quarter_ebitda is None\n",
    "            or self.stock_variation_3m is None\n",
    "        )\n",
    "\n",
    "\n",
    "class LeadCompleted(BaseModel):\n",
    "    \"\"\"Completed lead with all enrichment fields.\"\"\"\n",
    "\n",
    "    company: str = Field(..., description=\"Name of the company\")\n",
    "    industry: str = Field(..., description=\"Industry sector of the company\")\n",
    "    employee_count: int = Field(..., description=\"Number of employees at the company\")\n",
    "    revenue_musd: float = Field(..., description=\"Annual revenue in millions of USD\")\n",
    "    website: str = Field(..., description=\"Official website URL of the company\")\n",
    "    last_year_profit: float = Field(\n",
    "        ..., description=\"Company's profit for the last fiscal year in millions of USD\"\n",
    "    )\n",
    "    last_quarter_ebitda: float = Field(\n",
    "        ..., description=\"Company's EBITDA for the last quarter in millions of USD\"\n",
    "    )\n",
    "    stock_variation_3m: float = Field(\n",
    "        ..., description=\"Stock price variation over the last 3 months in percentage\"\n",
    "    )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated, Any, Optional\n",
    "\n",
    "from langgraph.graph.message import add_messages\n",
    "from pydantic import BaseModel, field_validator\n",
    "\n",
    "class IdealCustomerProfile(BaseModel):\n",
    "    \"\"\"Ideal Customer Profile criteria extracted from Google Sheets.\"\"\"\n",
    "    \n",
    "    industries_allowed: Optional[list[str]] = None\n",
    "    industries_blocked: Optional[list[str]] = None\n",
    "    employee_min: Optional[int] = None\n",
    "    employee_max: Optional[int] = None\n",
    "    regions_allowed: Optional[list[str]] = None\n",
    "    regions_blocked: Optional[list[str]] = None\n",
    "    technologies_required: Optional[list[str]] = None\n",
    "    buyer_personas: Optional[list[str]] = None\n",
    "    excluded_personas: Optional[list[str]] = None\n",
    "    \n",
    "    @classmethod\n",
    "    def parse_semicolon_list(cls, value: str) -> list[str]:\n",
    "        \"\"\"Parse semicolon-separated string into list.\"\"\"\n",
    "        if not value or not isinstance(value, str):\n",
    "            return []\n",
    "        return [item.strip() for item in value.split(';') if item.strip()]\n",
    "\n",
    "class State(BaseModel):\n",
    "    \"\"\"Application state for the B2B workflow graph.\"\"\"\n",
    "\n",
    "    messages: Annotated[list, add_messages]\n",
    "    leads: list[Lead] = []\n",
    "    filtered_leads: list[Lead] = []\n",
    "    next_action: str = \"\"\n",
    "    icp: Optional[IdealCustomerProfile] = None  # NEW: Store ICP data\n",
    "\n",
    "    @field_validator(\"leads\", \"filtered_leads\", mode=\"before\")\n",
    "    @classmethod\n",
    "    def validate_leads(cls, v: Any) -> list[Lead]:\n",
    "        \"\"\"Convert dicts to Lead objects.\"\"\"\n",
    "        if not v:\n",
    "            return []\n",
    "        if isinstance(v[0], dict):\n",
    "            return [Lead(**lead) if isinstance(lead, dict) else lead for lead in v]\n",
    "        return v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import Tool\n",
    "import pandas as pd\n",
    "\n",
    "def retrieve_icp_tool(llm: ChatOpenAI) -> Tool:\n",
    "    \"\"\"Tool that retrieves and parses ICP data using structured output.\"\"\"\n",
    "    \n",
    "    def _retrieve_icp(*args, **kwargs) -> IdealCustomerProfile:  # Accept both *args and **kwargs\n",
    "        \"\"\"Read ICP data from CSV and parse into structured IdealCustomerProfile format.\"\"\"\n",
    "        # Read raw data\n",
    "        df = pd.read_csv('ICP.csv')\n",
    "        icp_dict = dict(zip(df['Parameter'], df['Value']))\n",
    "        \n",
    "        # Format data for LLM parsing\n",
    "        data_str = \"\\n\".join([f\"{k}: {v}\" for k, v in icp_dict.items()])\n",
    "        \n",
    "        # Use structured output to parse\n",
    "        parser = llm.with_structured_output(IdealCustomerProfile)\n",
    "        \n",
    "        prompt = f\"\"\"\n",
    "        Parse the following Ideal Customer Profile (ICP) data into structured format.\n",
    "        \n",
    "        Raw Data:\n",
    "        {data_str}\n",
    "        \n",
    "        Extract and structure:\n",
    "        - Industries (allowed/blocked) - split semicolon-separated values into lists\n",
    "        - Employee count range (min/max) - convert to integers\n",
    "        - Regions (allowed/blocked) - split semicolon-separated values into lists\n",
    "        - Technologies required - split semicolon-separated values into lists\n",
    "        - Buyer personas - split semicolon-separated values into lists\n",
    "        - Excluded personas - split semicolon-separated values into lists\n",
    "        \"\"\"\n",
    "        \n",
    "        # Parse into structured format and return directly\n",
    "        icp = parser.invoke([{\"role\": \"user\", \"content\": prompt}])\n",
    "        return json.dumps(icp.model_dump())\n",
    "    \n",
    "    return Tool(\n",
    "        name=\"retrieve_icp\",\n",
    "        description=\"Retrieves and parses the Ideal Customer Profile (ICP) data.\",\n",
    "        func=_retrieve_icp,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chatbot_node(old_state: State, llm: ChatOpenAI, tools) -> dict:\n",
    "    \"\"\"Analyze user intent and route to appropriate workflow.\"\"\"\n",
    "\n",
    "    system_prompt = f\"\"\"\n",
    "    You are a helpful assistant that \n",
    "\n",
    "    # Instructions\n",
    "    - You can only perform two tasks:\n",
    "        - Find the ICP (Ideal Customer Profile)\n",
    "        - Find leads, if you already have the ICP (Ideal Customer Profile), you can use the tools to find leads.\n",
    "        - Use tools to get information about the correct user profile that client wants to find.\n",
    "    - You can use the following tools to find the ICP (Ideal Customer Profile):\n",
    "    {tools}\n",
    "    \"\"\"\n",
    "    \n",
    "    from langchain_core.messages import ToolMessage, SystemMessage\n",
    "    \n",
    "    # Get all messages first - always initialize\n",
    "    messages = list(old_state.messages) if old_state.messages else []\n",
    "    last_message = messages[-1] if messages else None\n",
    "    \n",
    "    # DEBUG: Print current state ICP\n",
    "    print(\"=\" * 80)\n",
    "    print(\"DEBUG: Current State ICP:\")\n",
    "    print(f\"  ICP in state: {old_state.icp}\")\n",
    "    if old_state.icp:\n",
    "        print(f\"  ICP type: {type(old_state.icp)}\")\n",
    "        print(f\"  ICP dict: {old_state.icp.model_dump()}\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    # If tool just executed, check if it's the ICP tool response\n",
    "    if isinstance(last_message, ToolMessage):\n",
    "        # Handle ICP object directly (or dict if serialized)\n",
    "        content = last_message.content\n",
    "        \n",
    "        # DEBUG: Print tool response\n",
    "        print(\"=\" * 80)\n",
    "        print(\"DEBUG: ToolMessage received:\")\n",
    "        print(f\"  Content type: {type(content)}\")\n",
    "        print(f\"  Content: {content}\")\n",
    "        if isinstance(content, dict):\n",
    "            print(f\"  Content keys: {content.keys() if hasattr(content, 'keys') else 'N/A'}\")\n",
    "        print(\"=\" * 80)\n",
    "        \n",
    "        icp_dict = json.loads(last_message.content)\n",
    "        icp = IdealCustomerProfile(**icp_dict)\n",
    "        \n",
    "        # Store ICP if we got it\n",
    "        if icp:\n",
    "            print(\"=\" * 80)\n",
    "            print(\"DEBUG: Storing ICP in state:\")\n",
    "            print(f\"  ICP object: {icp}\")\n",
    "            print(f\"  ICP model_dump(): {icp.model_dump()}\")\n",
    "            print(\"=\" * 80)\n",
    "            \n",
    "            return {\n",
    "                \"icp\": icp,\n",
    "                \"messages\": [{\"role\": \"assistant\", \"content\": \"ICP retrieved and stored successfully!\"}],\n",
    "                \"next_action\": \"end\",\n",
    "            }\n",
    "        \n",
    "        # For other tool responses, continue normal flow\n",
    "        # Add system message if needed\n",
    "        if not messages or not isinstance(messages[0], SystemMessage):\n",
    "            messages = [SystemMessage(content=system_prompt)] + messages\n",
    "    else:\n",
    "        # First call - add system message if needed\n",
    "        if not messages or not isinstance(messages[0], SystemMessage):\n",
    "            messages = [SystemMessage(content=system_prompt)] + messages\n",
    "    \n",
    "    # Normal LLM invocation (messages is always defined at this point)\n",
    "    llm_with_tools = llm.bind_tools(tools)\n",
    "    response = llm_with_tools.invoke(messages)\n",
    "\n",
    "    return {\n",
    "        \"messages\": [response],\n",
    "        \"next_action\": \"end\",\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_orchestrator_node(llm: ChatOpenAI, tools):\n",
    "    \"\"\"Create orchestrator node with LLM dependency.\"\"\"\n",
    "\n",
    "    def node(state: State) -> dict:\n",
    "        return chatbot_node(state, llm, tools)\n",
    "\n",
    "    return node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_lead_finder_node(llm, tools):\n",
    "    \"\"\"\n",
    "    Returns an agent node function that uses LLM with tools to find leads matching the user's ICP.\n",
    "    \"\"\"\n",
    "    def node(state: State) -> dict:\n",
    "        from langchain_core.messages import SystemMessage, ToolMessage\n",
    "        \n",
    "        # Get ICP from state\n",
    "        icp = state.icp if hasattr(state, \"icp\") else None\n",
    "        \n",
    "        if icp:\n",
    "            icp_info = f\"\\nUser's Ideal Customer Profile (ICP):\\n{icp.model_dump_json()}\\n\"\n",
    "        else:\n",
    "            icp_info = \"\\nNo Ideal Customer Profile (ICP) available. Please retrieve it first.\\n\"\n",
    "\n",
    "        system_prompt = (\n",
    "            f\"\"\"You are a lead-finding agent.\n",
    "            Use the following ICP to find matching leads:\n",
    "            {icp_info}\n",
    "\n",
    "            # Instructions\n",
    "            - Use the available tools to find leads that match the ICP criteria\n",
    "            - Find exactly 3 leads that match: industries, employee range, and regions from the ICP\n",
    "            - Each lead must have: company name, industry, employee_count, and revenue_musd\n",
    "            - Call tools to search for leads matching the ICP\n",
    "            \"\"\"\n",
    "        )\n",
    "\n",
    "        messages = list(state.messages) if state.messages else []\n",
    "        last_message = messages[-1] if messages else None\n",
    "        \n",
    "        # If tool just executed, extract leads from tool response using structured output\n",
    "        if isinstance(last_message, ToolMessage):\n",
    "            # Tool response received - parse it into Lead objects\n",
    "            tool_content = str(last_message.content)\n",
    "            \n",
    "            # Use structured output to parse tool response into leads\n",
    "            from pydantic import BaseModel\n",
    "            \n",
    "            class LeadList(BaseModel):\n",
    "                \"\"\"List of leads extracted from tool response.\"\"\"\n",
    "                leads: list[Lead]\n",
    "            \n",
    "            # Parse tool response into structured leads\n",
    "            parser = llm.with_structured_output(LeadList)\n",
    "            prompt = f\"\"\"\n",
    "            Extract leads from the following tool response.\n",
    "            Convert the information into Lead objects with: company, industry, employee_count, revenue_musd.\n",
    "            \n",
    "            Tool Response:\n",
    "            {tool_content}\n",
    "            \n",
    "            Extract exactly 3 leads that match the ICP criteria.\n",
    "            \"\"\"\n",
    "            \n",
    "            response = parser.invoke([{\"role\": \"user\", \"content\": prompt}])\n",
    "            leads = response.leads if hasattr(response, 'leads') else []\n",
    "            \n",
    "            return {\n",
    "                \"leads\": [lead.model_dump() for lead in leads],\n",
    "                \"messages\": [{\"role\": \"assistant\", \"content\": f\"Found {len(leads)} leads from tool results\"}],\n",
    "            }\n",
    "        \n",
    "        # First call or continuing - add system message and bind tools\n",
    "        if not messages or not isinstance(messages[0], SystemMessage):\n",
    "            messages = [SystemMessage(content=system_prompt)] + messages\n",
    "        \n",
    "        # Bind tools so LLM can call them\n",
    "        llm_with_tools = llm.bind_tools(tools)\n",
    "        response = llm_with_tools.invoke(messages)\n",
    "\n",
    "        return {\n",
    "            \"messages\": [response],\n",
    "        }\n",
    "\n",
    "    return node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.utilities import GoogleSerperAPIWrapper\n",
    "from langchain_core.tools import Tool\n",
    "\n",
    "\n",
    "def create_search_tool() -> Tool:\n",
    "    \"\"\"Create search tool for company information.\"\"\"\n",
    "    serper_search = GoogleSerperAPIWrapper()\n",
    "\n",
    "    return Tool(\n",
    "        name=\"search_company_info\",\n",
    "        description=(\n",
    "            \"Search the web for detailed information about a company including recent news, \"\n",
    "            \"technologies used, partnerships, and business updates. \"\n",
    "            \"Use this when you need more context about a lead company.\"\n",
    "        ),\n",
    "        func=serper_search.run,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.prebuilt import ToolNode, tools_condition\n",
    "from application.agents.summary_agent import create_summary_node  # Import the summary node\n",
    "\n",
    "llm = ChatOpenAI(model=\"gpt-4o-mini\")\n",
    "read_icp_tool = retrieve_icp_tool(llm)\n",
    "tools = [create_search_tool()]\n",
    "\n",
    "# Add summary agent\n",
    "summary_node = create_summary_node(llm)\n",
    "\n",
    "graph_builder = StateGraph(State)\n",
    "graph_builder.add_node(\"chatbot\", create_orchestrator_node(llm, [read_icp_tool]))\n",
    "graph_builder.add_node(\"tools\", ToolNode(tools=[read_icp_tool]))\n",
    "graph_builder.add_node(\"search_tool\", ToolNode(tools=tools))\n",
    "graph_builder.add_node(\"lead_finder\", create_lead_finder_node(llm, tools))\n",
    "graph_builder.add_node(\"summary\", summary_node)\n",
    "\n",
    "# Add conditional edge to route to tools when LLM calls a tool\n",
    "graph_builder.add_conditional_edges(\n",
    "    \"chatbot\",\n",
    "    tools_condition,  # This checks if there are tool calls in the response\n",
    "    {\n",
    "        \"tools\": \"tools\",  # Route to tools node if tool calls exist\n",
    "        \"__end__\": \"lead_finder\",     # Otherwise end\n",
    "    }\n",
    ")\n",
    "graph_builder.add_conditional_edges(\n",
    "    \"lead_finder\",\n",
    "    tools_condition,  # This checks if there are tool calls in the response\n",
    "    {\n",
    "        \"tools\": \"search_tool\",  # Route to tools node if tool calls exist\n",
    "        \"__end__\": \"summary\",     # Otherwise end\n",
    "    }\n",
    ")\n",
    "graph_builder.add_edge(\"tools\", \"chatbot\")\n",
    "graph_builder.add_edge(\"search_tool\", \"lead_finder\")\n",
    "graph_builder.add_edge(START, \"chatbot\")\n",
    "graph_builder.add_edge(\"summary\", END)\n",
    "\n",
    "graph = graph_builder.compile(checkpointer=memory)\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = {\"configurable\": {\"thread_id\": \"200000\"}}\n",
    "\n",
    "def chat(message, history):\n",
    "    \"\"\"Chat interface handler.\"\"\"\n",
    "    from langchain_core.messages import HumanMessage\n",
    "    \n",
    "    # Create new user message\n",
    "    new_message = HumanMessage(content=message)\n",
    "    \n",
    "    # Invoke graph - it will automatically load previous messages from checkpointer\n",
    "    result = graph.invoke(\n",
    "        {\"messages\": [new_message]},  # âœ… Only new message, checkpointer handles history\n",
    "        config=config\n",
    "    )\n",
    "    \n",
    "    print(\"State:\", result)\n",
    "    print(\"-\" * 100)\n",
    "    \n",
    "    # DEBUG: Print ICP from result\n",
    "    print(\"=\" * 80)\n",
    "    print(\"DEBUG: ICP in result state:\")\n",
    "    if \"icp\" in result:\n",
    "        icp = result[\"icp\"]\n",
    "        print(f\"  ICP: {icp}\")\n",
    "        print(f\"  ICP type: {type(icp)}\")\n",
    "        if icp:\n",
    "            print(f\"  ICP model_dump(): {icp.model_dump()}\")\n",
    "            print(f\"  Industries allowed: {icp.industries_allowed}\")\n",
    "            print(f\"  Employee range: {icp.employee_min} - {icp.employee_max}\")\n",
    "            print(f\"  Regions allowed: {icp.regions_allowed}\")\n",
    "    else:\n",
    "        print(\"  No ICP in result\")\n",
    "    print(\"=\" * 80)\n",
    "    \n",
    "    # Get the last message content\n",
    "    last_message = result[\"messages\"][-1]\n",
    "    if hasattr(last_message, 'content'):\n",
    "        return last_message.content\n",
    "    return str(last_message)\n",
    "\n",
    "gr.ChatInterface(\n",
    "    chat,\n",
    "    title=\"B2B Lead Generation Assistant\",\n",
    "    description=\"Ask me to find and qualify B2B leads!\",\n",
    ").launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# pd.read_csv('icp.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "B2B Agent (Python 3.12)",
   "language": "python",
   "name": "b2b-agent"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
