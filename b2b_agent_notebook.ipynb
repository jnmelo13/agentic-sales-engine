{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# B2B Agent Workflow\n",
    "\n",
    "This notebook demonstrates the B2B Agent multi-agent workflow system for lead finding, collection, and enrichment.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.message import add_messages\n",
    "from dotenv import load_dotenv\n",
    "from IPython.display import Image, display\n",
    "import gradio as gr\n",
    "from langgraph.graph import StateGraph\n",
    "from langgraph.graph.message import add_messages\n",
    "from langchain_openai import ChatOpenAI\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import Optional\n",
    "import random\n",
    "from langchain_core.messages import ToolMessage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Lead(BaseModel):\n",
    "    \"\"\"Structured lead with enrichment fields\"\"\"\n",
    "    company: str\n",
    "    industry: str\n",
    "    employee_count: int\n",
    "    revenue_musd: float\n",
    "    \n",
    "    # Enrichment fields - initially None\n",
    "    website: Optional[str] = None\n",
    "    last_year_profit: Optional[float] = None      \n",
    "    last_quarter_ebitda: Optional[float] = None\n",
    "    stock_variation_3m: Optional[float] = None\n",
    "    \n",
    "    def needs_enrichment(self) -> bool:\n",
    "        \"\"\"Check if lead still needs enrichment\"\"\"\n",
    "        return (\n",
    "            self.website is None or\n",
    "            self.last_year_profit is None or\n",
    "            self.last_quarter_ebitda is None or\n",
    "            self.stock_variation_3m is None\n",
    "        )\n",
    "\n",
    "class lead_completed(BaseModel):\n",
    "    company: str = Field(..., description=\"Name of the company\")\n",
    "    industry: str = Field(..., description=\"Industry sector of the company\")\n",
    "    employee_count: int = Field(..., description=\"Number of employees at the company\")\n",
    "    revenue_musd: float = Field(..., description=\"Annual revenue in millions of USD\")\n",
    "    website: str = Field(..., description=\"Official website URL of the company\")\n",
    "    last_year_profit: float = Field(..., description=\"Company's profit for the last fiscal year in millions of USD\")\n",
    "    last_quarter_ebitda: float = Field(..., description=\"Company's EBITDA for the last quarter in millions of USD\")\n",
    "    stock_variation_3m: float = Field(..., description=\"Stock price variation over the last 3 months in percentage\")\n",
    "    \n",
    "\n",
    "# Base class to define a state\n",
    "class State(BaseModel):\n",
    "    messages: Annotated[list, add_messages]\n",
    "    leads: list[Lead] = [] \n",
    "    filtered_leads: list[Lead] = [] \n",
    "    # enriched_lead: Optional[Lead] = None\n",
    "    next_action: str = \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_leads(state: State) -> dict:\n",
    "    # Simulating the leads\n",
    "    leads = [\n",
    "        Lead(\n",
    "            company=\"Americanas S.A.\",\n",
    "            industry=\"Marketplace\",\n",
    "            employee_count=1200,\n",
    "            revenue_musd=12.4\n",
    "        ),\n",
    "        Lead(\n",
    "            company=\"Grupo Madero\",\n",
    "            industry=\"food\",\n",
    "            employee_count=400,\n",
    "            revenue_musd=0.1\n",
    "        ),\n",
    "        Lead(\n",
    "            company=\"Grupo Boticário\",\n",
    "            industry=\"Beauty & Personal Care\",\n",
    "            employee_count=250,\n",
    "            revenue_musd=1\n",
    "        )\n",
    "    ]\n",
    "    \n",
    "    # Return updates as a dict (LangGraph will merge with state)\n",
    "    return {\n",
    "        \"leads\": [lead.model_dump() for lead in leads],\n",
    "        \"messages\": [{\"role\": \"assistant\", \"content\": f\"Found {len(leads)} leads\"}]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def triage(state: State) -> dict:\n",
    "    print(\"TRIAGE\")\n",
    "    # Access leads from state\n",
    "    leads = state.leads if hasattr(state, 'leads') else []\n",
    "\n",
    "    # Apply simple rules to filter leads\n",
    "    filtered = []\n",
    "    for lead in leads:\n",
    "        if (\n",
    "            lead.employee_count >= 0 and\n",
    "            lead.revenue_musd >= 0 and\n",
    "            lead.industry != \"logistics\"\n",
    "        ):\n",
    "            filtered.append(lead)\n",
    "    \n",
    "    print(\"\"\"=== FILTERED LEADS ===\"\"\")\n",
    "    for lead in filtered:\n",
    "        print(lead)\n",
    "    # Return updates as a dict\n",
    "    return {\n",
    "        \"filtered_leads\": [lead.model_dump() for lead in filtered],\n",
    "        \"messages\": [{\"role\": \"assistant\", \"content\": f\"Filtered to {len(filtered)} qualified leads: {filtered}\"}]\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Starting a new graph\n",
    "graph_builder = StateGraph(State)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create nodes\n",
    "graph_builder.add_node(\"lead_finder\", get_leads);\n",
    "graph_builder.add_node(\"triage\", triage);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Edges\n",
    "graph_builder.add_edge(START, \"lead_finder\");\n",
    "graph_builder.add_edge(\"lead_finder\", \"triage\");\n",
    "graph_builder.add_edge(\"triage\", END);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = graph_builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.invoke(State(messages=[{\"role\": \"user\", \"content\": \"Hello\"}]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def chat(user_input: str, history):\n",
    "#     message = {\"role\": \"user\", \"content\": user_input}\n",
    "#     messages = [message]\n",
    "#     state = State(messages=messages)\n",
    "#     result = graph.invoke(state)\n",
    "#     print(result)\n",
    "#     return result[\"messages\"][-1].content\n",
    "\n",
    "\n",
    "# gr.ChatInterface(chat, type=\"messages\").launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graph + LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading env variables\n",
    "load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(model=\"gpt-4o-mini\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chatbot_node(old_state: State) -> dict:\n",
    "    # Ask LLM to analyze intent\n",
    "    system_msg = {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": \"If user wants to find leads, respond with EXACTLY 'FIND_LEADS'. Otherwise chat normally.\"\n",
    "    }\n",
    "    messages = [system_msg] + old_state.messages\n",
    "    response = llm.invoke(messages)\n",
    "    \n",
    "    # Check if LLM wants to trigger lead finding\n",
    "    if \"FIND_LEADS\" in response.content:\n",
    "        # Don't show \"FIND_LEADS\" to user - show a friendly transitional message\n",
    "        return {\n",
    "            \"messages\": [{\"role\": \"assistant\", \"content\": \"Great! Let me find some qualified leads for you...\"}],\n",
    "            \"next_action\": \"find_leads\"\n",
    "        }\n",
    "    else:\n",
    "        # Normal chat - show the actual LLM response\n",
    "        return {\n",
    "            \"messages\": [{\"role\": \"assistant\", \"content\": response.content}],\n",
    "            \"next_action\": \"end\"\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.utilities import GoogleSerperAPIWrapper\n",
    "from langchain_core.tools import Tool\n",
    "from langgraph.prebuilt import ToolNode, tools_condition\n",
    "\n",
    "\n",
    "# Tool to find more information for a lead\n",
    "serper_search = GoogleSerperAPIWrapper()\n",
    "\n",
    "search_tool = Tool(\n",
    "    name=\"search_company_info\",\n",
    "    description=\"Search the web for detailed information about a company including recent news, technologies used, partnerships, and business updates. Use this when you need more context about a lead company.\",\n",
    "    func=serper_search.run\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# search_tool.invoke(\"Tell me the Brazilian company Americanas S.A. revenue for 2024\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tools = [search_tool]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def enrich_leads(state: State) -> dict:\n",
    "    \"\"\"LLM decides if leads need enrichment using the search tool.\"\"\"\n",
    "    filtered = state.filtered_leads\n",
    "    \n",
    "    if not filtered:\n",
    "        return {\"filtered_leads\": []}\n",
    "    \n",
    "    # Check if any leads still need enrichment\n",
    "    leads_needing_enrichment = [lead for lead in filtered if lead.needs_enrichment()]\n",
    "    print(\"-\"*100)\n",
    "    print(leads_needing_enrichment)\n",
    "    print(\"-\"*100)\n",
    "    \n",
    "    if not leads_needing_enrichment:\n",
    "        # All leads are enriched, end the loop\n",
    "        return {\n",
    "            \"messages\": [{\"role\": \"assistant\", \"content\": \"All leads have been enriched!\"}]\n",
    "        }\n",
    "    \n",
    "    # Only enrich one company at a time to avoid repetition\n",
    "    lead_to_enrich = leads_needing_enrichment[0]\n",
    "\n",
    "    # ⭐ KEY FIX: Check if we just received tool results\n",
    "    last_message = state.messages[-1] if state.messages else None\n",
    "    \n",
    "    if isinstance(last_message, ToolMessage):\n",
    "        # We have tool results - don't request tools again, let it go to update_lead\n",
    "        print(f\"✓ Tool results received for {lead_to_enrich.company}, proceeding to update...\")\n",
    "        return {\n",
    "            \"messages\": [{\"role\": \"assistant\", \"content\": f\"Processing results for {lead_to_enrich.company}\"}],\n",
    "            # \"enriched_lead\": lead_to_enrich\n",
    "        }\n",
    "    \n",
    "    system_prompt = f\"\"\"You are enriching lead data for {lead_to_enrich.company}.\n",
    "    \n",
    "    Current data: {lead_to_enrich.model_dump_json()}\n",
    "    \n",
    "    Use search_company_info to find ONLY the missing fields. Be specific in your search query.\n",
    "    After getting results, extract the relevant information clearly.\"\"\"\n",
    "    \n",
    "    messages = state.messages + [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "        {\"role\": \"user\", \"content\": f\"Find missing information for {lead_to_enrich.company}\"}\n",
    "    ]\n",
    "    \n",
    "    llm_with_tools = llm.bind_tools(tools)\n",
    "    response = llm_with_tools.invoke(messages)\n",
    "    \n",
    "    return {\n",
    "        \"messages\": [response],\n",
    "        # \"enriched_lead\": lead_to_enrich\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_lead(state: State) -> dict:\n",
    "    print(\"UPDATE LEAD\")\n",
    "    # Find the first lead that needs enrichment (this is the one we just got results for)\n",
    "    lead_to_update = next((l for l in state.filtered_leads if l.needs_enrichment()), None)\n",
    "    \n",
    "    if not lead_to_update:\n",
    "        return {}\n",
    "\n",
    "    extractor = llm.with_structured_output(lead_completed)\n",
    "\n",
    "    prompt = f\"\"\"\n",
    "    Combine the existing lead and the search results, and output a full LeadCompleted object.\n",
    "\n",
    "    Existing lead: {lead_to_update.model_dump_json()}\n",
    "    Search results: {state.messages[-1].content}\n",
    "    \"\"\"\n",
    "\n",
    "    enriched = extractor.invoke([{\"role\": \"user\", \"content\": prompt}])\n",
    "    filtered = state.filtered_leads\n",
    "\n",
    "    updated = [\n",
    "        enriched.model_dump() if lead.company == enriched.company else lead.model_dump()\n",
    "        for lead in filtered\n",
    "    ]\n",
    "\n",
    "    return {\"filtered_leads\": updated}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def should_continue(state: State):\n",
    "    return (\n",
    "        \"enricher\"\n",
    "        if any(l.needs_enrichment() for l in state.filtered_leads)\n",
    "        else END\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_summary(state: State) -> dict:\n",
    "    \"\"\"Generate natural language summary of results\"\"\"\n",
    "    filtered = state.filtered_leads if hasattr(state, 'filtered_leads') else []\n",
    "    \n",
    "    system_msg = {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": f\"\"\"Summarize these B2B leads in a friendly way:\n",
    "        Initial informations:\n",
    "        {filtered}\n",
    "\n",
    "        # Instructions\n",
    "        - Use markdown to format the summary\n",
    "        \"\"\"\n",
    "    }\n",
    "    \n",
    "    messages = [system_msg] + state.messages\n",
    "    response = llm.invoke(messages)\n",
    "    \n",
    "    return {\n",
    "        \"messages\": [{\"role\": \"assistant\", \"content\": response.content}]\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Starting a new graph\n",
    "graph_builder = StateGraph(State)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create nodes\n",
    "graph_builder.add_node(\"lead_finder\", get_leads);\n",
    "graph_builder.add_node(\"triage\", triage);\n",
    "graph_builder.add_node(\"chatbot\", chatbot_node);\n",
    "graph_builder.add_node(\"summary\", generate_summary);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_builder.add_node(\"enricher\", enrich_leads)\n",
    "graph_builder.add_node(\"tools\", ToolNode(tools=tools))\n",
    "graph_builder.add_node(\"update_lead\", update_lead)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Routing logic\n",
    "def route_after_chatbot(state: State) -> str:\n",
    "    # Access the attribute directly (Pydantic BaseModel)\n",
    "    next_action = state.next_action\n",
    "    print(f\"Routing decision: {next_action}\")\n",
    "    return \"lead_finder\" if next_action == \"find_leads\" else END"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Edges\n",
    "graph_builder.add_edge(START, \"chatbot\")\n",
    "graph_builder.add_conditional_edges(\"chatbot\", route_after_chatbot, {\n",
    "    \"lead_finder\": \"lead_finder\",\n",
    "    END: END\n",
    "})\n",
    "graph_builder.add_edge(\"lead_finder\", \"triage\")\n",
    "graph_builder.add_edge(\"triage\", \"enricher\")\n",
    "\n",
    "graph_builder.add_conditional_edges(\n",
    "    \"enricher\", \n",
    "    tools_condition,\n",
    "    {\n",
    "        \"tools\": \"tools\",        # If tool calls exist, execute them\n",
    "        \"__end__\": \"update_lead\" # Otherwise, go to update_lead\n",
    "    }\n",
    ")\n",
    "\n",
    "# After tools execute, back to enricher for next iteration\n",
    "graph_builder.add_edge(\"tools\", \"enricher\")\n",
    "\n",
    "# After update, check if more enrichment needed\n",
    "graph_builder.add_conditional_edges(\n",
    "    \"update_lead\",\n",
    "    should_continue,\n",
    "    {\n",
    "        \"enricher\": \"enricher\",  # Continue with next lead\n",
    "        END: \"summary\"           # ← Changed: Go to summary instead of END\n",
    "    }\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = graph_builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat(user_input: str, history):\n",
    "    message = {\"role\": \"user\", \"content\": user_input}\n",
    "    messages = [message]\n",
    "    state = State(messages=messages)\n",
    "    result = graph.invoke(state)\n",
    "    print(\"State %\",state)\n",
    "    print(\"-\"*100)\n",
    "    print(\"Result %\",result)\n",
    "    return result[\"messages\"][-1].content\n",
    "\n",
    "\n",
    "gr.ChatInterface(\n",
    "    chat, \n",
    "    type=\"messages\",\n",
    "    title=\"B2B Lead Generation Assistant\",\n",
    "    description=\"Ask me to find and qualify B2B leads!\"\n",
    ").launch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "B2B Agent (Python 3.12)",
   "language": "python",
   "name": "b2b-agent"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
